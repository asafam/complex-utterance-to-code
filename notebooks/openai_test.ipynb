{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "\n",
    "paths = ['../src/', '../src/api/v6']\n",
    "for path in paths:\n",
    "    path = os.path.normcase(path)\n",
    "    if not any(os.path.normcase(sp) == path for sp in sys.path):\n",
    "        sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from transformers import GPT2TokenizerFast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = os.getenv(\"OPENAI_API_ORG\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build prompt from the API docstrings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_spec_prompt():\n",
    "    prompt_dict = {}\n",
    "    for prompt_file in glob.glob('../config/prompts/*.txt'):\n",
    "        key = os.path.basename(prompt_file).split('.')[0].lower()\n",
    "        with open(prompt_file, \"r\") as f:\n",
    "            prompt_dict[key] = f.read()\n",
    "    \n",
    "    prompt = \"\"\n",
    "    for key, value in prompt_dict.items():\n",
    "        prompt = prompt + f\"# {key.upper()}:\\n\\n{value}\\n\\n\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20659"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = build_spec_prompt()\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "len(tokenizer(prompt, max_length=51200, truncation=True)[\"input_ids\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples prompt**\n",
    "\n",
    "\n",
    "Building a prompt from the text and code examples generated by the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/asaf/Workspace/biu/complex-utterance-to-code/build/train_complex_utterance_to_code_with_intermediate_40k.csv.gz'\n",
    "examples_df = pd.read_csv(file_path)\n",
    "examples_df = examples_df.reset_index()  # make sure indexes pair with number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_example_prompt(text, code=None):\n",
    "    examples_prompt = f\"text: \\n{text}\\n\\n\"\n",
    "    examples_prompt += f\"code: \\n{code}\\n\\n\\n\" if code else f\"code: \\n\"\n",
    "    \n",
    "    return examples_prompt\n",
    "\n",
    "\n",
    "def build_examples_prompt(examples_prompt, df, limit=10):\n",
    "    examples_prompt = examples_prompt or \"\"\n",
    "    for index, row in df[:limit].iterrows():\n",
    "        examples_prompt += build_example_prompt(text=row['text'], code=row['code'])\n",
    "    \n",
    "    return examples_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3417"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_prompt = \"\"\"\n",
    "Transform text to code\n",
    "\n",
    "# EXAMPLES:\n",
    "\n",
    "\"\"\"\n",
    "prompt = build_examples_prompt(examples_prompt, examples_df, limit=18)\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "len(tokenizer(prompt, max_length=51200, truncation=True)[\"input_ids\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'eval_complex_utterance_to_code_with_intermediate_82_20230509.csv.gz'\n",
    "base_path = '/Users/asaf/Workspace/biu/complex-utterance-to-code/build'\n",
    "eval_df = pd.read_csv(os.path.join(base_path, file_name))\n",
    "eval_df = eval_df.reset_index()  # make sure indexes pair with number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df[\"code\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_code(code: str, imports: str, test: str, code_embed_str: str = '# end code block to test', fail_on_error: bool = False, verbose: str = 'Fatal'):\n",
    "  try:\n",
    "    code_insert_idx = test.find(code_embed_str)\n",
    "    program_code = imports\n",
    "    program_code += '\\n'\n",
    "    program_code += test[:code_insert_idx]\n",
    "    program_code += code\n",
    "    program_code += '\\n'\n",
    "    program_code += test[code_insert_idx:]\n",
    "  except Exception as e:\n",
    "    if verbose == 'Error':\n",
    "      print('[ERROR] Failed to unparse code rep to code\\n', e)\n",
    "    if fail_on_error:\n",
    "      raise e\n",
    "    program_code = ''\n",
    "  finally:\n",
    "    return program_code\n",
    "\n",
    "def eval_code(code: str):\n",
    "  test_results = {}\n",
    "  try:\n",
    "    context = {}\n",
    "    exec(code, context)\n",
    "    test_results = context.get('test_results', {})\n",
    "  except AssertionError as e:\n",
    "    test_results['test_failuers'] = test_results.get('test_failuers', 0) + 1\n",
    "  except Exception as e:\n",
    "    test_results['code_failure'] = test_results.get('code_failure', 0) + 1\n",
    "  \n",
    "  return test_results\n",
    "  \n",
    "\n",
    "def compute_scores(df, index):\n",
    "  # df = pd.DataFrame(data)\n",
    "  df = df.set_index(index).sort_index()\n",
    "  df['correct'] = df['results'].apply(lambda test_results: test_results.get('correct', 0))\n",
    "  df['incorrect'] = df['results'].apply(lambda test_results: test_results.get('incorrect', 0))\n",
    "  df['total'] = df['correct'] + df['incorrect']\n",
    "  df['code_failure'] = df['results'].apply(lambda test_results: test_results.get('code_failure', 0))\n",
    "  df['score'] = ((1 - df['code_failure']) * (df['correct'] / df['total'])).replace({np.nan: 0})\n",
    "\n",
    "  return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['babbage', 'davinci', 'text-davinci-edit-001', 'whisper-1', 'babbage-code-search-code', 'text-similarity-babbage-001', 'code-davinci-edit-001', 'text-davinci-001', 'ada', 'babbage-code-search-text', 'babbage-similarity', 'code-search-babbage-text-001', 'text-curie-001', 'code-search-babbage-code-001', 'text-ada-001', 'text-embedding-ada-002', 'text-similarity-ada-001', 'curie-instruct-beta', 'gpt-3.5-turbo', 'ada-code-search-code', 'ada-similarity', 'code-search-ada-text-001', 'text-search-ada-query-001', 'davinci-search-document', 'gpt-3.5-turbo-0301', 'ada-code-search-text', 'text-search-ada-doc-001', 'davinci-instruct-beta', 'text-similarity-curie-001', 'code-search-ada-code-001', 'ada-search-query', 'text-search-davinci-query-001', 'curie-search-query', 'davinci-search-query', 'babbage-search-document', 'ada-search-document', 'gpt-4-0314', 'text-search-curie-query-001', 'text-search-babbage-doc-001', 'gpt-4', 'curie-search-document', 'text-davinci-003', 'text-search-curie-doc-001', 'babbage-search-query', 'text-babbage-001', 'text-search-davinci-doc-001', 'text-search-babbage-query-001', 'curie-similarity', 'curie', 'text-similarity-davinci-001', 'text-davinci-002', 'davinci-similarity', 'cushman:2020-05-03', 'ada:2020-05-03', 'babbage:2020-05-03', 'curie:2020-05-03', 'davinci:2020-05-03', 'if-davinci-v2', 'if-curie-v2', 'if-davinci:3.0.0', 'davinci-if:3.0.0', 'davinci-instruct-beta:2.0.0', 'text-ada:001', 'text-davinci:001', 'text-curie:001', 'text-babbage:001']\n"
     ]
    }
   ],
   "source": [
    "oai_models = openai.Model.list()\n",
    "print([model_data['id'] for model_data in oai_models['data']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['babbage-code-search-code', 'code-davinci-edit-001', 'babbage-code-search-text', 'code-search-babbage-text-001', 'code-search-babbage-code-001', 'ada-code-search-code', 'code-search-ada-text-001', 'ada-code-search-text', 'code-search-ada-code-001']\n"
     ]
    }
   ],
   "source": [
    "print([model_data['id'] for model_data in oai_models['data'] if 'code' in model_data['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Model model id=babbage at 0x166040810> JSON: {\n",
       "  \"created\": 1649358449,\n",
       "  \"id\": \"babbage\",\n",
       "  \"object\": \"model\",\n",
       "  \"owned_by\": \"openai\",\n",
       "  \"parent\": null,\n",
       "  \"permission\": [\n",
       "    {\n",
       "      \"allow_create_engine\": false,\n",
       "      \"allow_fine_tuning\": false,\n",
       "      \"allow_logprobs\": true,\n",
       "      \"allow_sampling\": true,\n",
       "      \"allow_search_indices\": false,\n",
       "      \"allow_view\": true,\n",
       "      \"created\": 1669085501,\n",
       "      \"group\": null,\n",
       "      \"id\": \"modelperm-49FUp5v084tBB49tC4z8LPH5\",\n",
       "      \"is_blocking\": false,\n",
       "      \"object\": \"model_permission\",\n",
       "      \"organization\": \"*\"\n",
       "    }\n",
       "  ],\n",
       "  \"root\": \"babbage\"\n",
       "}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text-davinci-003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'text-davinci-003'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221d07a0b1834ab788eafd1ea1650240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing records:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4251\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 11565 tokens (10565 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[253], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m prompt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m build_example_prompt(text\u001b[39m=\u001b[39mrow[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(prompt\u001b[39m.\u001b[39msplit()) \u001b[39m+\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(engine\u001b[39m=\u001b[39;49mMODEL_NAME, prompt\u001b[39m=\u001b[39;49mprompt, max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m responses\u001b[39m.\u001b[39mappend(response)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/biu/lib/python3.9/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/biu/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/biu/lib/python3.9/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/biu/lib/python3.9/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    629\u001b[0m         ),\n\u001b[1;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/biu/lib/python3.9/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 11565 tokens (10565 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "examples_prompt = \"\"\"\n",
    "Transform text to code\n",
    "\n",
    "# EXAMPLES:\n",
    "\n",
    "\"\"\"\n",
    "base_prompt = build_examples_prompt(examples_prompt, examples_df, limit=25)\n",
    "\n",
    "responses = []\n",
    "for i, row  in tqdm_notebook(eval_df.iterrows(), total=eval_df.shape[0], desc=\"Processing records\"):\n",
    "    prompt = base_prompt\n",
    "    prompt += build_example_prompt(text=row['text'])\n",
    "    print(len(prompt.split()) + 1000)\n",
    "    \n",
    "    response = openai.Completion.create(engine=MODEL_NAME, prompt=prompt, max_tokens=1000)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00df12d368e64109a1358df779a91e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing records:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 16622 tokens (15622 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[241], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m prompt \u001b[39m=\u001b[39m base_prompt\n\u001b[1;32m      5\u001b[0m prompt \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m build_example_prompt(text\u001b[39m=\u001b[39mrow[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(engine\u001b[39m=\u001b[39;49mMODEL_NAME, prompt\u001b[39m=\u001b[39;49mprompt, max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m responses\u001b[39m.\u001b[39mappend(response)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/biu/lib/python3.9/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/biu/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/biu/lib/python3.9/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/biu/lib/python3.9/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    629\u001b[0m         ),\n\u001b[1;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/biu/lib/python3.9/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 16622 tokens (15622 in your prompt; 1000 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "samples_df = eval_df[:2]\n",
    "for i, row  in tqdm_notebook(samples_df.iterrows(), total=samples_df.shape[0], desc=\"Processing records\"):\n",
    "    prompt = base_prompt\n",
    "    prompt += build_example_prompt(text=row['text'])\n",
    "    \n",
    "    response = openai.Completion.create(engine=MODEL_NAME, prompt=prompt, max_tokens=1000)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = pd.DataFrame(responses)\n",
    "responses_df.to_csv(f'../build/openai-{MODEL_NAME}-{file_name}', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     walmart_availability = Store.check_availabilit...\n",
       "1     date_time = DateTime.resolve_from_text(\"tomorr...\n",
       "2     date_time = DateTime.resolve_from_text(\"tomorr...\n",
       "3     music_source = MusicSource.resolve_from_text(\"...\n",
       "4     recipient = Recipient.resolve_from_text(\"Dad\")...\n",
       "                            ...                        \n",
       "77    spotify_playlist_name = \"lofi\"\\nMediaPlayer.pl...\n",
       "78    date_time = DateTime.resolve_from_text(\"tonigh...\n",
       "79    date_time = DateTime.resolve_from_text(\"tonigh...\n",
       "80    date_time_start = DateTime.resolve_from_text(\"...\n",
       "81    date_time_tomorrow = DateTime.resolve_from_tex...\n",
       "Name: choices, Length: 82, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responses_df['choices'].apply(lambda choices: choices[0]['text'] if choices else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'test_id', 'sample_id', 'sample_minor_id', 'text', 'code',\n",
       "       'test', 'imports', 'lang_rep', 'code_rep', 'generated_code'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df['generated_code'] = responses_df['choices'].apply(lambda choices: choices[0]['text'] if choices else None)\n",
    "eval_df['test_code'] = eval_df.apply(lambda row: build_test_code(code=row['generated_code'], imports=row['imports'], test=row['test']), axis=1)\n",
    "eval_df['results'] = eval_df['test_code'].apply(lambda code: eval_code(code))\n",
    "\n",
    "scores_df = compute_scores(eval_df, index='sample_id')\n",
    "scores_df.groupby('sample_id')['score'].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'text-davinci-003'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0717aaf589904d5cb3083c0bca656866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing records:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples_prompt = \"\"\"\n",
    "Transform text to code\n",
    "\n",
    "# EXAMPLES:\n",
    "\n",
    "\"\"\"\n",
    "base_prompt = build_examples_prompt(examples_prompt, examples_df, limit=13)\n",
    "\n",
    "responses = []\n",
    "for i, row  in tqdm_notebook(eval_df.iterrows(), total=eval_df.shape[0], desc=\"Processing records\"):\n",
    "    prompt = base_prompt\n",
    "    prompt += build_example_prompt(text=row['text'])\n",
    "    \n",
    "    response = openai.Completion.create(engine=MODEL_NAME, prompt=prompt, max_tokens=1000)\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_df = pd.DataFrame(responses)\n",
    "responses_df.to_csv(f'../build/openai-{MODEL_NAME}-{file_name}', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     walmart_availability = Store.check_availabilit...\n",
       "1     date_time = DateTime.resolve_from_text(\"tomorr...\n",
       "2     date_time = DateTime.resolve_from_text(\"tomorr...\n",
       "3     music_source = MusicSource.resolve_from_text(\"...\n",
       "4     recipient = Recipient.resolve_from_text(\"Dad\")...\n",
       "                            ...                        \n",
       "77    spotify_playlist_name = \"lofi\"\\nMediaPlayer.pl...\n",
       "78    date_time = DateTime.resolve_from_text(\"tonigh...\n",
       "79    date_time = DateTime.resolve_from_text(\"tonigh...\n",
       "80    date_time_start = DateTime.resolve_from_text(\"...\n",
       "81    date_time_tomorrow = DateTime.resolve_from_tex...\n",
       "Name: choices, Length: 82, dtype: object"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_df['choices'].apply(lambda choices: choices[0]['text'] if choices else None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'test_id', 'sample_id', 'sample_minor_id', 'text', 'code',\n",
       "       'test', 'imports', 'lang_rep', 'code_rep', 'generated_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0625"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['generated_code'] = responses_df['choices'].apply(lambda choices: choices[0]['text'] if choices else None)\n",
    "eval_df['test_code'] = eval_df.apply(lambda row: build_test_code(code=row['generated_code'], imports=row['imports'], test=row['test']), axis=1)\n",
    "eval_df['results'] = eval_df['test_code'].apply(lambda code: eval_code(code))\n",
    "\n",
    "scores_df = compute_scores(eval_df, index='sample_id')\n",
    "scores_df.groupby('sample_id')['score'].mean().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gpt-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL_NAME = 'text-gpt4'\n",
    "model = openai.Model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_legs</th>\n",
       "      <th>num_wings</th>\n",
       "      <th>num_specimen_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>falcon</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spider</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_legs  num_wings  num_specimen_seen\n",
       "falcon         2          2                 10\n",
       "dog            4          0                  2\n",
       "spider         8          0                  1\n",
       "fish           0          0                  8"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
    "                   'num_wings': [2, 0, 0, 0],\n",
    "                   'num_specimen_seen': [10, 2, 1, 8]},\n",
    "                  index=['falcon', 'dog', 'spider', 'fish'])\n",
    "df2 = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
    "                   'num_wings': [2, 0, 0, 0],\n",
    "                   'num_specimen_seen': [10, 2, 1, 8]},)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_legs</th>\n",
       "      <th>num_wings</th>\n",
       "      <th>num_specimen_seen</th>\n",
       "      <th>num_legs</th>\n",
       "      <th>num_wings</th>\n",
       "      <th>num_specimen_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>falcon</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spider</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num_legs  num_wings  num_specimen_seen  num_legs  num_wings  \\\n",
       "falcon       2.0        2.0               10.0       NaN        NaN   \n",
       "dog          4.0        0.0                2.0       NaN        NaN   \n",
       "spider       8.0        0.0                1.0       NaN        NaN   \n",
       "fish         0.0        0.0                8.0       NaN        NaN   \n",
       "0            NaN        NaN                NaN       2.0        2.0   \n",
       "1            NaN        NaN                NaN       4.0        0.0   \n",
       "2            NaN        NaN                NaN       8.0        0.0   \n",
       "3            NaN        NaN                NaN       0.0        0.0   \n",
       "\n",
       "        num_specimen_seen  \n",
       "falcon                NaN  \n",
       "dog                   NaN  \n",
       "spider                NaN  \n",
       "fish                  NaN  \n",
       "0                    10.0  \n",
       "1                     2.0  \n",
       "2                     1.0  \n",
       "3                     8.0  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "module = evaluate.load(\"dvitel/codebleu\")\n",
    "src = 'class AcidicSwampOoze(MinionCard):§    def __init__(self):§        super().__init__(\"Acidic Swamp Ooze\", 2, CHARACTER_CLASS.ALL, CARD_RARITY.COMMON, battlecry=Battlecry(Destroy(), WeaponSelector(EnemyPlayer())))§§    def create_minion(self, player):§        return Minion(3, 2)§'\n",
    "tgt = 'class AcidSwampOoze(MinionCard):§    def __init__(self):§        super().__init__(\"Acidic Swamp Ooze\", 2, CHARACTER_CLASS.ALL, CARD_RARITY.COMMON, battlecry=Battlecry(Destroy(), WeaponSelector(EnemyPlayer())))§§    def create_minion(self, player):§        return Minion(3, 2)§'\n",
    "src = src.replace(\"§\",\"\\n\")\n",
    "tgt = tgt.replace(\"§\",\"\\n\")\n",
    "res = module.compute(predictions = [tgt], references = [[src]])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:biu] *",
   "language": "python",
   "name": "conda-env-biu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
