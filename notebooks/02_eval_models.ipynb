{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmtLl76F8A8B"
      },
      "source": [
        "# Train Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lteNoO4kIahi"
      },
      "source": [
        "Based on https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/T5/Fine_tune_CodeT5_for_generating_docstrings_from_Ruby_code.ipynb#scrollTo=wvRHDkCIS91f and https://colab.research.google.com/drive/1d4xNsZbDSZ5ZqXgZjy7HyTVRLBJBVsh6#scrollTo=SDVQ04fGRb1v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-7bq0hWR3ny"
      },
      "source": [
        "## Set-up environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRTrTycCMiDk"
      },
      "source": [
        "Let's first install the required libraries:\n",
        "* HuggingFace Transformers (for the CodeT5 model)\n",
        "* HuggingFace Datasets (for loading the dataset + preprocessing it)\n",
        "* PyTorch Lightning (for training)\n",
        "* Weights and Biases (for logging training metrics).\n",
        "* Project code from a GitHub repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8n4pEe2RXFB",
        "outputId": "0a228ca2-d08c-4c4c-a372-6a72ebd9fe26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/__init__.py\", line 17, in <module>\n",
            "    _IMPORT_CWD = os.path.abspath(os.getcwd())\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers sentencepiece pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8IoXMEQx4gF",
        "outputId": "030e4391-af7c-481f-8a32-bf50285e5054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive\n",
            "sample_data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "rm: cannot remove '/content/complex-utterance-to-code': No such file or directory\n",
            "Cloning into '/content/complex-utterance-to-code'...\n",
            "fatal: Unable to read current working directory: Transport endpoint is not connected\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "rm -r /content/complex-utterance-to-code\n",
        "git clone https://github.com/asafam/complex-utterance-to-code.git /content/complex-utterance-to-code\n",
        "ls /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os \n",
        "\n",
        "WORK_AREA = \"/Users/asaf/Workspace/biu/complex-utterance-to-code\"\n",
        "os.chdir(WORK_AREA)\n",
        "\n",
        "paths = ['./src/', './src/api/v6', './notebooks/src/']\n",
        "for path in paths:\n",
        "    path = os.path.normcase(path)\n",
        "    if not any(os.path.normcase(sp) == path for sp in sys.path):\n",
        "        sys.path.append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qtrgijePOeB6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "paths = [\n",
        "  '/content/complex-utterance-to-code', \n",
        "  '/content/complex-utterance-to-code/notebooks/src',\n",
        "  '/content/complex-utterance-to-code/src', \n",
        "  '/content/complex-utterance-to-code/src/api/v6', \n",
        "]\n",
        "for path in paths:\n",
        "  path = os.path.normcase(path)\n",
        "  if not any(os.path.normcase(sp) == path for sp in sys.path):\n",
        "      sys.path.append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdaMbQFUMB-9",
        "outputId": "af8d4a7d-8676-4191-e358-afe3942087fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/asaf/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x2a1b45ed0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Union, List\n",
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "import math\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "import tokenize\n",
        "from nltk.translate import bleu_score\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
        "import textwrap\n",
        "from sklearn import metrics\n",
        "import statistics\n",
        "\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    RobertaTokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "from data.dataset import ComplexUtteranceCodeDataset\n",
        "from data.utils import (\n",
        "    get_dataset_args,\n",
        "    load_test_data,\n",
        ")\n",
        "from eval.utils import (\n",
        "    eval_generated_code,\n",
        "    model_eval,\n",
        ")\n",
        "\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItWCqHFnMV28",
        "outputId": "a5046c6b-2ba3-449e-a832-babd69d73217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "WORK_DRIVE = '/content/drive'\n",
        "WORK_AREA = WORK_DRIVE + '/MyDrive/university/masters/complex_utterances_semantic_parsing/notebooks'\n",
        "\n",
        "drive.mount(WORK_DRIVE)\n",
        "os.chdir(WORK_AREA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu50z1gUIahm"
      },
      "source": [
        "### Model configuration code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HioPvr2JIahm"
      },
      "outputs": [],
      "source": [
        "def load_tokenizer(pretrained_model_name_or_path):\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(pretrained_model_name_or_path)\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "def load_model(pretrained_model_name_or_path):\n",
        "    print(f\"Loading model from {pretrained_model_name_or_path}\")\n",
        "    model = T5ForConditionalGeneration.from_pretrained(pretrained_model_name_or_path)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3YGEo4StlUcz"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "\n",
        "class ModelFlavour(Enum):\n",
        "    Text2Code = \"text2code\"\n",
        "    Text2Rep = \"text2rep\"\n",
        "    Rep2Code = \"rep2code\"\n",
        "    Rep2Rep = \"rep2rep\"\n",
        "    TextRep2Rep = \"textrep2rep\"\n",
        "    TextRep2Code = \"textrep2code\"\n",
        "\n",
        "\n",
        "class Model(Enum):\n",
        "    T5Base = \"t5-base\"\n",
        "    CodeT5Small = \"codet5-small\"\n",
        "    CodeT5Base = \"codet5-base\"\n",
        "    CodeT5P220m = \"codet5p-220m\"\n",
        "\n",
        "\n",
        "model_flavour_params = {\n",
        "    ModelFlavour.Text2Code: dict(\n",
        "        slug = \"text2code\",\n",
        "        input_prefix = \"text to code: \",\n",
        "        input_label = \"text\",\n",
        "        target_label = \"code\",\n",
        "    ),\n",
        "    ModelFlavour.Text2Rep: dict(\n",
        "        slug = \"text2rep\",\n",
        "        input_prefix = \"text to rep: \",\n",
        "        input_label = \"text\",\n",
        "        target_label = \"code_rep\",\n",
        "    ),\n",
        "    ModelFlavour.Rep2Code: dict(\n",
        "        slug = \"rep2code\",\n",
        "        input_prefix = \"rep to code: \",\n",
        "        input_label = \"lang_rep\",\n",
        "        target_label = \"code\",\n",
        "    ),\n",
        "    ModelFlavour.Rep2Rep: dict(\n",
        "        slug = \"rep2rep\",\n",
        "        input_prefix = \"rep to rep: \",\n",
        "        input_label = \"lang_rep\",\n",
        "        target_label = \"code_rep\",\n",
        "    ),\n",
        "    ModelFlavour.TextRep2Rep: dict(\n",
        "        slug = \"text_rep2rep\",\n",
        "        input_prefix = \"text and rep to rep: \",\n",
        "        input_label = \"text_lang_rep\",\n",
        "        target_label = \"code_rep\",\n",
        "    ),\n",
        "    ModelFlavour.TextRep2Code: dict(\n",
        "        slug = \"textrep2code\",\n",
        "        input_prefix = \"text and rep to code: \",\n",
        "        input_label = \"text_lang_rep\",\n",
        "        target_label = \"code\",\n",
        "    ),\n",
        "}\n",
        "\n",
        "pretrained_model_names_mapping = {\n",
        "    Model.T5Base: \"t5-base\",\n",
        "    Model.CodeT5Small: \"Salesforce/codet5-small\",\n",
        "    Model.CodeT5Base: \"Salesforce/codet5-base\",\n",
        "    Model.CodeT5P220m: \"Salesforce/codet5p-220m\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bg_MuR7DB-vp"
      },
      "outputs": [],
      "source": [
        "from typing import List, Union, Optional, TypeVar, Generic\n",
        "import os\n",
        "import pandas as pd\n",
        "import ast\n",
        "import math\n",
        "import glob\n",
        "from representations.tree.tree import Tree\n",
        "from representations.builders.ast.tearers.tearer_factory import TearerFactory\n",
        "import tokenize\n",
        "from nltk.translate import bleu_score\n",
        "from sklearn import metrics\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def parse_code_rep_to_code(code_rep: str, verbose: str = \"Fatal\") -> str:\n",
        "    try:\n",
        "        tree = Tree.unparse(code_rep)\n",
        "        tearer = TearerFactory().get_tearer(tree.root_node)\n",
        "        asdl = tearer.tear(tree.root_node)\n",
        "        code = ast.unparse(asdl)\n",
        "    except Exception as e:\n",
        "        if verbose == \"Error\":\n",
        "            print(f\"[Error] failed to prase code rep to code:\\n\", e)\n",
        "        code = \"\"\n",
        "    finally:\n",
        "        return code\n",
        "\n",
        "\n",
        "def build_test_code(\n",
        "    code: str,\n",
        "    imports: str,\n",
        "    test: str,\n",
        "    code_embed_str: str = \"# end code block to test\",\n",
        "    fail_on_error: bool = False,\n",
        "    verbose: str = \"Fatal\",\n",
        "):\n",
        "    try:\n",
        "        code_insert_idx = test.find(code_embed_str)\n",
        "        program_code = imports\n",
        "        program_code += \"\\n\"\n",
        "        program_code += test[:code_insert_idx]\n",
        "        program_code += code\n",
        "        program_code += \"\\n\"\n",
        "        program_code += test[code_insert_idx:]\n",
        "    except Exception as e:\n",
        "        if verbose == \"Error\":\n",
        "            print(\"[ERROR] Failed to unparse code rep to code\\n\", e)\n",
        "        if fail_on_error:\n",
        "            raise e\n",
        "        program_code = \"\"\n",
        "    finally:\n",
        "        return program_code\n",
        "\n",
        "\n",
        "def tokenize_source(code):\n",
        "    file_path = \"/tmp/example.py\"\n",
        "\n",
        "    with open(file_path, \"w\") as text_file:\n",
        "        text_file.write(code)\n",
        "\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        tokens_gen = tokenize.tokenize(f.readline)\n",
        "\n",
        "        tokens = [token.string for token in tokens_gen]\n",
        "\n",
        "    os.remove(file_path)\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def eval_code(code: str):\n",
        "    test_results = {}\n",
        "    try:\n",
        "        context = {}\n",
        "        exec(code, context)\n",
        "        test_results = context.get(\"test_results\", {})\n",
        "    except AssertionError as e:\n",
        "        test_results[\"test_failuers\"] = test_results.get(\"test_failuers\", 0) + 1\n",
        "    except Exception as e:\n",
        "        test_results[\"code_failure\"] = test_results.get(\"code_failure\", 0) + 1\n",
        "\n",
        "    code_failure = test_results.get(\"code_failure\", 0)\n",
        "    correct = test_results.get(\"correct\", 0)\n",
        "    incorrect = test_results.get(\"incorrect\", 0)\n",
        "    total = (correct + incorrect) or math.inf\n",
        "    accuracy = (1 - code_failure) * (correct / total)\n",
        "\n",
        "    results = dict(\n",
        "        code_failure=code_failure,\n",
        "        correct=correct,\n",
        "        incorrect=incorrect,\n",
        "        accuracy=accuracy,\n",
        "    )\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def eval_bleu(code, generated_code):\n",
        "    hypothesis = tokenize_source(code)\n",
        "    reference = tokenize_source(generated_code)\n",
        "    weights = (0.25, 0.25, 0.25, 0.25)\n",
        "    score = bleu_score.sentence_bleu([reference], hypothesis, weights=weights)\n",
        "    return score\n",
        "\n",
        "\n",
        "def generate_code(\n",
        "    model, tokenizer, dataloader, gold_column, id_labels, max_length\n",
        "):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    targets = []\n",
        "    ids = {}\n",
        "    for id_label in id_labels:\n",
        "        ids[id_label] = []\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        outs = model.generate(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            max_length=max_length,\n",
        "        )\n",
        "\n",
        "        output = [tokenizer.decode(out, skip_special_tokens=True) for out in outs]\n",
        "        target = [t.strip() for t in batch[gold_column]]\n",
        "\n",
        "        outputs.extend(output)\n",
        "        targets.extend(target)\n",
        "        for id_label in id_labels:\n",
        "            ids[id_label].extend(batch[id_label])\n",
        "\n",
        "    data = pd.DataFrame(\n",
        "        {\n",
        "            \"output\": outputs,\n",
        "            \"target\": targets,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def eval_model(data: pd.DataFrame):\n",
        "    results = dict(\n",
        "        exact=metrics.accuracy_score(data[\"target\"], data[\"output\"]),\n",
        "        bleu=None,\n",
        "        humaneval=eval_model_humaneval(data[\"target\"], data[\"output\"]),\n",
        "    )\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def humaneval_accuracy_score(\n",
        "    data: pd.DataFrame,\n",
        "    code_column_name: str = \"pred_code\",\n",
        "    score_id_labels: Union[str, List[str]] = \"sample_id\",\n",
        "    score_column_name: str = \"accuracy\",\n",
        "):\n",
        "    test_codes = data.apply(\n",
        "        lambda x: build_test_code(\n",
        "            code=x[code_column_name], imports=x[\"imports\"], test=x[\"test\"]\n",
        "        ),\n",
        "        axis=1,\n",
        "    )\n",
        "    test_results = test_codes.apply(lambda test_code: eval_code(test_code))\n",
        "    test_results_df = pd.DataFrame.from_records(\n",
        "        test_results.values, index=test_results.index\n",
        "    )\n",
        "    score = (\n",
        "        test_results_df.reset_index(drop=False)\n",
        "        .groupby(score_id_labels)[score_column_name]\n",
        "        .mean()\n",
        "        .mean()\n",
        "    )\n",
        "    return dict(score=score, results=test_results_df)\n",
        "\n",
        "\n",
        "def bleu_accuracy_score(\n",
        "    data: pd.DataFrame,\n",
        "    generated_column=\"output\",\n",
        "    gold_column=\"code\",\n",
        "    score_id_labels: Union[str, List[str]] = \"sample_id\",\n",
        "    score_column_name: str = \"bleu_score\",\n",
        "):\n",
        "    eval_results = data.apply(\n",
        "        lambda x: eval_bleu(x[gold_column], x[generated_column]), axis=1\n",
        "    )\n",
        "    eval_results_df = eval_results.to_frame(\"bleu_score\")\n",
        "    score = (\n",
        "        eval_results_df.reset_index(drop=False)\n",
        "        .groupby(score_id_labels)[score_column_name]\n",
        "        .mean()\n",
        "        .mean()\n",
        "    )\n",
        "    return dict(score=score, results=eval_results_df)\n",
        "\n",
        "\n",
        "def model_eval(\n",
        "    results_df,\n",
        "    output_column=\"output\",\n",
        "    gold_column=\"code\",\n",
        "    parse_to_code=False,\n",
        "    compute_humanval=True,\n",
        "    compute_bleu=True,\n",
        "):\n",
        "    results_df[\"sample_id\"] = results_df[\"sample_id\"].astype(int)\n",
        "    results_df.set_index([\"sample_id\", \"sample_minor_id\"], inplace=True)\n",
        "    results_df.sort_index(inplace=True)\n",
        "\n",
        "    code_column = \"generated_code\"\n",
        "    if parse_to_code:\n",
        "        results_df[code_column] = results_df[output_column].apply(\n",
        "            lambda x: parse_code_rep_to_code(x)\n",
        "        )\n",
        "    else:\n",
        "        results_df[code_column] = results_df[output_column]\n",
        "\n",
        "    results_df[\"test\"] = results_df[\"test\"].str.replace(\n",
        "        \"= next(iterator)\", \"= next(iterator, None)\"\n",
        "    )\n",
        "    results_df[code_column] = results_df[code_column].str.replace(\n",
        "        \" = ContentType.\", \" = MessageContentType.\"\n",
        "    )\n",
        "    results_df[code_column] = results_df[code_column].str.replace(\n",
        "        \"Message.\", \"Messages.\"\n",
        "    )\n",
        "\n",
        "    humaneval_results = (\n",
        "        humaneval_accuracy_score(data=results_df, code_column_name=code_column)\n",
        "        if compute_humanval\n",
        "        else {}\n",
        "    )\n",
        "\n",
        "    bleu_results = (\n",
        "        bleu_accuracy_score(\n",
        "            data=results_df, generated_column=code_column, gold_column=gold_column\n",
        "        )\n",
        "        if compute_bleu\n",
        "        else {}\n",
        "    )\n",
        "\n",
        "    results = dict(humaneval=humaneval_results, bleu=bleu_results)\n",
        "    return results\n",
        "\n",
        "\n",
        "def eval_model_humaneval(\n",
        "    data: pd.DataFrame,\n",
        "    code_column_name: str = \"pred_code\",\n",
        "    score_id_labels: Union[str, List[str]] = \"sample_id\",\n",
        "    score_column_name: str = \"accuracy\",\n",
        "):\n",
        "    test_codes = data.apply(\n",
        "        lambda x: build_test_code(\n",
        "            code=x[code_column_name], imports=x[\"imports\"], test=x[\"test\"]\n",
        "        ),\n",
        "        axis=1,\n",
        "    )\n",
        "    test_results = test_codes.apply(lambda test_code: eval_code(test_code))\n",
        "\n",
        "    test_results_df = pd.DataFrame.from_records(\n",
        "        test_results.values, index=test_results.index\n",
        "    )\n",
        "    score = (\n",
        "        test_results_df.reset_index(drop=False)\n",
        "        .groupby(score_id_labels)[score_column_name]\n",
        "        .mean()\n",
        "        .mean()\n",
        "    )\n",
        "    return score, test_results_df\n",
        "\n",
        "\n",
        "def eval_bleu(code, generated_code):\n",
        "    hypothesis = tokenize_source(code)\n",
        "    reference = tokenize_source(generated_code)\n",
        "    n = max(min(len(hypothesis), 4), 1)\n",
        "    weight = 1 / n\n",
        "    weights = (weight,) * n\n",
        "    score = bleu_score.sentence_bleu([reference], hypothesis, weights=weights)\n",
        "    return score\n",
        "\n",
        "\n",
        "def eval_generated_code(\n",
        "    df,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    dataloader,\n",
        "    target_label,\n",
        "    id_labels,\n",
        "    max_length,\n",
        "    output_column=\"output\",\n",
        "    gold_column=\"code\",\n",
        "    parse_code=False,\n",
        "    file_path=None,\n",
        "):\n",
        "    eval_df = generate_code(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        dataloader=dataloader,\n",
        "        gold_column=target_label,\n",
        "        id_labels=id_labels,\n",
        "        max_length=max_length,\n",
        "    )\n",
        "\n",
        "    if file_path:\n",
        "        df2 = df.join(eval_df.set_index(df.index))\n",
        "        df2.to_csv(file_path)\n",
        "        print(f\"Results were saved to {file_path}\")\n",
        "\n",
        "    results = model_eval(\n",
        "        results_file_path=file_path,\n",
        "        parse_to_code=parse_code,\n",
        "        compute_humanval=True,\n",
        "        compute_bleu=True,\n",
        "        output_column=output_column,\n",
        "        gold_column=gold_column,\n",
        "    )\n",
        "    print(f\"humaneval = {results['humaneval']['score']}\")\n",
        "    print(f\"bleu = {results['bleu']['score']}\")\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY7kNWtAIahm"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckyCLXaAIahm"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIMjhgO8Iahm",
        "outputId": "74fb532a-87d3-4fae-f0c9-c769943d37ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape =  (92, 12)\n",
            "test_df (92, 12)\n",
            "test_df (92, 12)\n"
          ]
        }
      ],
      "source": [
        "test_file_path = 'data/eval_complex_utterance_to_code_with_intermediate_82_20230519.csv.gz'\n",
        "test_df = load_test_data(test_file_path=test_file_path, id_labels=None)\n",
        "print(\"test_df\", test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJzYnUiQIahn"
      },
      "outputs": [],
      "source": [
        "def eval_test_data(pretrained_model_path, test_df, model_architecture, selected_model_type):\n",
        "    # create a tokenizer and load the model\n",
        "    pretrained_model_name_or_path = pretrained_model_names_mapping[model_architecture]\n",
        "    tokenizer = load_tokenizer(pretrained_model_name_or_path)\n",
        "    model = load_model(pretrained_model_path)\n",
        "\n",
        "    # selected model params    \n",
        "    selected_model_flavour_params = model_flavour_params[selected_model_type]\n",
        "    target_label = selected_model_flavour_params.get('target_label')\n",
        "    slug = selected_model_flavour_params.get('slug')\n",
        "    parse_code = selected_model_flavour_params.get(target_label) == 'code_rep'\n",
        "\n",
        "    # load the dataset\n",
        "    dataset_args = get_dataset_args(tokenizer, selected_model_flavour_params)\n",
        "    max_length = dataset_args['max_target_length']\n",
        "    \n",
        "    test_dataset = ComplexUtteranceCodeDataset(data=test_df, **dataset_args)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=4, num_workers=12)\n",
        "    \n",
        "    model_id = model_architecture.value\n",
        "    pretrained_model_file = [x for x in pretrained_model_path.split('/') if x][-1]\n",
        "    test_results_file_path = f\"results/test-{str(test_df.shape[0])}-{pretrained_model_file}.csv.gz\"\n",
        "    id_labels = ['test_id', 'sample_id', 'sample_minor_id']\n",
        "\n",
        "    print(f\"model_id = {model_id}\")\n",
        "    print(f\"slug = {slug}\")\n",
        "\n",
        "    results = eval_generated_code(\n",
        "        df=test_df, \n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        dataloader=test_dataloader, \n",
        "        target_label=target_label,\n",
        "        id_labels=id_labels,\n",
        "        max_length=max_length,\n",
        "        gold_column='code', \n",
        "        parse_code=parse_code,\n",
        "        file_path=test_results_file_path,\n",
        "    )\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zWy4k4_Iahm",
        "outputId": "f1541010-a24e-46c4-e6a7-90a8559e4475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drwx------ 2 root root 4096 May 18 20:13 codet5p-220m-rep2rep-2023-05-18_181859\n",
            "drwx------ 2 root root 4096 May 18 22:32 codet5p-220m-text2code-2023-05-18_202622\n",
            "drwx------ 2 root root 4096 May 19 12:31 codet5p-220m-textrep2rep-2023-05-19_102443\n",
            "drwx------ 2 root root 4096 May 19 15:16 codet5p-220m-rep2code-2023-05-19_130954\n",
            "drwx------ 2 root root 4096 May 19 16:54 codet5p-220m-text2rep-2023-05-19_151621\n",
            "drwx------ 2 root root 4096 May 19 23:10 codet5p-220m-textrep2code-2023-05-19_205000\n",
            "drwx------ 2 root root 4096 May 20 12:52 codet5p-220m-text2code-2023-05-20_103245\n",
            "drwx------ 2 root root 4096 May 20 15:03 codet5p-220m-rep2rep-2023-05-20_125703\n",
            "drwx------ 2 root root 4096 May 21 01:50 codet5p-220m-text2code-2023-05-20_233005\n"
          ]
        }
      ],
      "source": [
        "!ls -ltra ./experiments | grep -i codet5p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "76696e64a8a44f67989d5ed4b559b6f8",
            "1afa8c7b703148aca0ff450aeb01f875",
            "1b093e57cb8e461e897a8ee742b9eaac",
            "10aea940ea6846d58b593191e881e613",
            "3f994969d7f7457098cbc0290a72c16f",
            "72cb47ec1a474d5ca9c8f27b4c5ce735",
            "b52876e946f0469ea3653116f52f0eeb",
            "97256f5a7f584b92943ee8ed047f1736",
            "a8c862162c71427ebc8d6b8980da0ff2",
            "4a28c771515745d1a181b10117df90e9",
            "9d002f760db94ecf9269b5f3f274dd73"
          ]
        },
        "id": "pvL1w1IpIahn",
        "outputId": "f74624cd-82ae-4bfa-f3c3-54c484d0c3a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./experiments/refit_complex_codet5-small-rep2rep-2023-05-23_031926/\n",
            "Loading model from ./experiments/refit_complex_codet5-small-rep2rep-2023-05-23_031926/\n",
            "model_id = codet5-small\n",
            "slug = rep2rep\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76696e64a8a44f67989d5ed4b559b6f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/23 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results were saved to results/codet5-small-rep2rep-test-92-.csv.gz\n"
          ]
        },
        {
          "ename": "TokenError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTokenError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-a1a271ffb92c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mselected_model_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'selected_model_type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCodeT5Small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_model_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-8da93c7767ad>\u001b[0m in \u001b[0;36meval_test_data\u001b[0;34m(pretrained_model_path, test_df, model_architecture, selected_model_type)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"slug = {slug}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     results = eval_generated_code(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/complex-utterance-to-code/notebooks/src/eval/utils.py\u001b[0m in \u001b[0;36meval_generated_code\u001b[0;34m(df, model, tokenizer, dataloader, target_label, id_labels, max_length, output_column, gold_column, parse_code, file_path)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Results were saved to {file_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     results = model_eval(\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0mresults_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mparse_to_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/complex-utterance-to-code/notebooks/src/eval/utils.py\u001b[0m in \u001b[0;36mmodel_eval\u001b[0;34m(results_file_path, output_column, gold_column, parse_to_code, compute_humanval, compute_bleu)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     bleu_results = (\n\u001b[0;32m--> 234\u001b[0;31m         bleu_accuracy_score(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgold_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         )\n",
            "\u001b[0;32m/content/complex-utterance-to-code/notebooks/src/eval/utils.py\u001b[0m in \u001b[0;36mbleu_accuracy_score\u001b[0;34m(data, generated_column, gold_column, score_id_labels, score_column_name)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mscore_column_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bleu_score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m ):\n\u001b[0;32m--> 182\u001b[0;31m     eval_results = data.apply(\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgold_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerated_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9566\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9567\u001b[0m         )\n\u001b[0;32m-> 9568\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9570\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/complex-utterance-to-code/notebooks/src/eval/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    181\u001b[0m ):\n\u001b[1;32m    182\u001b[0m     eval_results = data.apply(\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgold_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerated_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     )\n\u001b[1;32m    185\u001b[0m     \u001b[0meval_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bleu_score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/complex-utterance-to-code/notebooks/src/eval/utils.py\u001b[0m in \u001b[0;36meval_bleu\u001b[0;34m(code, generated_code)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/complex-utterance-to-code/notebooks/src/eval/utils.py\u001b[0m in \u001b[0;36mtokenize_source\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtokens_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/complex-utterance-to-code/notebooks/src/eval/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtokens_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tokenize.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m                                  \u001b[0;31m# continued statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTokenError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EOF in multi-line statement\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m             \u001b[0mcontinued\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTokenError\u001b[0m: ('EOF in multi-line statement', (2, 0))"
          ]
        }
      ],
      "source": [
        "models_args = [\n",
        "    dict(selected_model_type=ModelFlavour.Rep2Rep, pretrained_model_path='./experiments/refit_complex_codet5-small-rep2rep-2023-05-23_031926/'),\n",
        "]\n",
        "\n",
        "for args in models_args:\n",
        "  pretrained_model_path = args.get('pretrained_model_path')\n",
        "  selected_model_type = args.get('selected_model_type')\n",
        "  print(pretrained_model_path)\n",
        "  \n",
        "  results = eval_test_data(pretrained_model_path, test_df, Model.CodeT5Small, selected_model_type)\n",
        "  print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "a3GQC13_dV6O",
        "outputId": "485dcc74-dfca-47d5-e3f0-209e37a7f388"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>test_id</th>\n",
              "      <th>sample_id</th>\n",
              "      <th>sample_minor_id</th>\n",
              "      <th>text</th>\n",
              "      <th>code</th>\n",
              "      <th>test</th>\n",
              "      <th>imports</th>\n",
              "      <th>lang_rep</th>\n",
              "      <th>code_rep</th>\n",
              "      <th>text_lang_rep</th>\n",
              "      <th>lang_rep_pretty</th>\n",
              "      <th>code_rep_pretty</th>\n",
              "      <th>output</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>40_b</td>\n",
              "      <td>40</td>\n",
              "      <td>b</td>\n",
              "      <td>If I don't have anything scheduled on the 20th...</td>\n",
              "      <td>date_time = DateTime.resolve_from_text(\"20th o...</td>\n",
              "      <td># test data\\ndata_model = DataModel(reset=True...</td>\n",
              "      <td>from entities.generic import *\\nfrom entities....</td>\n",
              "      <td>[ root [ S [ Command [ Condition [ If [ Test [...</td>\n",
              "      <td>[ Module [ date_time = DateTime.resolve_from_t...</td>\n",
              "      <td>Text: If I don't have anything scheduled on th...</td>\n",
              "      <td>[ root [ S [ Command [ Condition [ If [ Test [...</td>\n",
              "      <td>[ Module [ date_time = DateTime.resolve_from_t...</td>\n",
              "      <td>[ Module [ event_calendar = EventCalendar.res...</td>\n",
              "      <td>[ Module [ date_time = DateTime.resolve_from_t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>19_b</td>\n",
              "      <td>19</td>\n",
              "      <td>b</td>\n",
              "      <td>Check the weather in Indianapolis, and if it's...</td>\n",
              "      <td>location = Location.resolve_from_text(\"Indiana...</td>\n",
              "      <td># test data\\ndata_model = DataModel(reset=True...</td>\n",
              "      <td>from entities.generic import *\\nfrom entities....</td>\n",
              "      <td>[ root [ S [ Command [ Action [ hd [ Check ] ]...</td>\n",
              "      <td>[ Module [ location = Location.resolve_from_te...</td>\n",
              "      <td>Text: Check the weather in Indianapolis, and i...</td>\n",
              "      <td>[ root [ S [ Command [ Action [ hd [ Check ] ]...</td>\n",
              "      <td>[ Module [ location = Location.resolve_from_te...</td>\n",
              "      <td>[ Module [ location = Location.resolve_from_t...</td>\n",
              "      <td>[ Module [ location = Location.resolve_from_te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>63_a</td>\n",
              "      <td>63</td>\n",
              "      <td>a</td>\n",
              "      <td>If the weather is going to be sunny Saturday m...</td>\n",
              "      <td>weather_attribute = WeatherAttribute.resolve_f...</td>\n",
              "      <td># test data\\ndata_model = DataModel(reset=True...</td>\n",
              "      <td>from entities.generic import *\\nfrom entities....</td>\n",
              "      <td>[ root [ S [ Command [ Condition [ If [ Test [...</td>\n",
              "      <td>[ Module [ weather_attribute = WeatherAttribut...</td>\n",
              "      <td>Text: If the weather is going to be sunny Satu...</td>\n",
              "      <td>[ root [ S [ Command [ Condition [ If [ Test [...</td>\n",
              "      <td>[ Module [ weather_attribute = WeatherAttribut...</td>\n",
              "      <td>[ Module [ weather_forecasts = Weather.find_w...</td>\n",
              "      <td>[ Module [ weather_attribute = WeatherAttribut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Message my brother I will not be able to make ...</td>\n",
              "      <td>message_content_type = MessageContentType.reso...</td>\n",
              "      <td># test data\\ndata_model = DataModel(reset=True...</td>\n",
              "      <td>from entities.generic import *\\nfrom entities....</td>\n",
              "      <td>[ root [ S [ Command [ Action [ advcl [ Comman...</td>\n",
              "      <td>[ Module [ message_content_type = MessageConte...</td>\n",
              "      <td>Text: Message my brother I will not be able to...</td>\n",
              "      <td>[ root [ S [ Command [ Action [ advcl [ Comman...</td>\n",
              "      <td>[ Module [ message_content_type = MessageConte...</td>\n",
              "      <td>[ Module [ message_content_type = MessageMess...</td>\n",
              "      <td>[ Module [ message_content_type = MessageConte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Check the availability of Pepsi at Walmart and...</td>\n",
              "      <td>product_name = ProductName.resolve_from_text(\"...</td>\n",
              "      <td># test data\\ndata_model = DataModel(reset=True...</td>\n",
              "      <td>from entities.generic import *\\nfrom entities....</td>\n",
              "      <td>[ root [ S [ Command [ Action [ hd [ Check ] ]...</td>\n",
              "      <td>[ Module [ product_name = ProductName.resolve_...</td>\n",
              "      <td>Text: Check the availability of Pepsi at Walma...</td>\n",
              "      <td>[ root [ S [ Command [ Action [ hd [ Check ] ]...</td>\n",
              "      <td>[ Module [ product_name = ProductName.resolve_...</td>\n",
              "      <td>[ Module [ product_name = ProductName.resolve...</td>\n",
              "      <td>[ Module [ product_name = ProductName.resolve_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 test_id  sample_id sample_minor_id   \n",
              "0           0    40_b         40               b  \\\n",
              "1           1    19_b         19               b   \n",
              "2           2    63_a         63               a   \n",
              "3           3      80         80             NaN   \n",
              "4           4       0          0             NaN   \n",
              "\n",
              "                                                text   \n",
              "0  If I don't have anything scheduled on the 20th...  \\\n",
              "1  Check the weather in Indianapolis, and if it's...   \n",
              "2  If the weather is going to be sunny Saturday m...   \n",
              "3  Message my brother I will not be able to make ...   \n",
              "4  Check the availability of Pepsi at Walmart and...   \n",
              "\n",
              "                                                code   \n",
              "0  date_time = DateTime.resolve_from_text(\"20th o...  \\\n",
              "1  location = Location.resolve_from_text(\"Indiana...   \n",
              "2  weather_attribute = WeatherAttribute.resolve_f...   \n",
              "3  message_content_type = MessageContentType.reso...   \n",
              "4  product_name = ProductName.resolve_from_text(\"...   \n",
              "\n",
              "                                                test   \n",
              "0  # test data\\ndata_model = DataModel(reset=True...  \\\n",
              "1  # test data\\ndata_model = DataModel(reset=True...   \n",
              "2  # test data\\ndata_model = DataModel(reset=True...   \n",
              "3  # test data\\ndata_model = DataModel(reset=True...   \n",
              "4  # test data\\ndata_model = DataModel(reset=True...   \n",
              "\n",
              "                                             imports   \n",
              "0  from entities.generic import *\\nfrom entities....  \\\n",
              "1  from entities.generic import *\\nfrom entities....   \n",
              "2  from entities.generic import *\\nfrom entities....   \n",
              "3  from entities.generic import *\\nfrom entities....   \n",
              "4  from entities.generic import *\\nfrom entities....   \n",
              "\n",
              "                                            lang_rep   \n",
              "0  [ root [ S [ Command [ Condition [ If [ Test [...  \\\n",
              "1  [ root [ S [ Command [ Action [ hd [ Check ] ]...   \n",
              "2  [ root [ S [ Command [ Condition [ If [ Test [...   \n",
              "3  [ root [ S [ Command [ Action [ advcl [ Comman...   \n",
              "4  [ root [ S [ Command [ Action [ hd [ Check ] ]...   \n",
              "\n",
              "                                            code_rep   \n",
              "0  [ Module [ date_time = DateTime.resolve_from_t...  \\\n",
              "1  [ Module [ location = Location.resolve_from_te...   \n",
              "2  [ Module [ weather_attribute = WeatherAttribut...   \n",
              "3  [ Module [ message_content_type = MessageConte...   \n",
              "4  [ Module [ product_name = ProductName.resolve_...   \n",
              "\n",
              "                                       text_lang_rep   \n",
              "0  Text: If I don't have anything scheduled on th...  \\\n",
              "1  Text: Check the weather in Indianapolis, and i...   \n",
              "2  Text: If the weather is going to be sunny Satu...   \n",
              "3  Text: Message my brother I will not be able to...   \n",
              "4  Text: Check the availability of Pepsi at Walma...   \n",
              "\n",
              "                                     lang_rep_pretty   \n",
              "0  [ root [ S [ Command [ Condition [ If [ Test [...  \\\n",
              "1  [ root [ S [ Command [ Action [ hd [ Check ] ]...   \n",
              "2  [ root [ S [ Command [ Condition [ If [ Test [...   \n",
              "3  [ root [ S [ Command [ Action [ advcl [ Comman...   \n",
              "4  [ root [ S [ Command [ Action [ hd [ Check ] ]...   \n",
              "\n",
              "                                     code_rep_pretty   \n",
              "0  [ Module [ date_time = DateTime.resolve_from_t...  \\\n",
              "1  [ Module [ location = Location.resolve_from_te...   \n",
              "2  [ Module [ weather_attribute = WeatherAttribut...   \n",
              "3  [ Module [ message_content_type = MessageConte...   \n",
              "4  [ Module [ product_name = ProductName.resolve_...   \n",
              "\n",
              "                                              output   \n",
              "0   [ Module [ event_calendar = EventCalendar.res...  \\\n",
              "1   [ Module [ location = Location.resolve_from_t...   \n",
              "2   [ Module [ weather_forecasts = Weather.find_w...   \n",
              "3   [ Module [ message_content_type = MessageMess...   \n",
              "4   [ Module [ product_name = ProductName.resolve...   \n",
              "\n",
              "                                              target  \n",
              "0  [ Module [ date_time = DateTime.resolve_from_t...  \n",
              "1  [ Module [ location = Location.resolve_from_te...  \n",
              "2  [ Module [ weather_attribute = WeatherAttribut...  \n",
              "3  [ Module [ message_content_type = MessageConte...  \n",
              "4  [ Module [ product_name = ProductName.resolve_...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = pd.read_csv('./dist/experiments_results/codet5-small-rep2rep-test-92-refit_complex_codet5-small-rep2rep-2023-05-23_031926.csv.gz')\n",
        "results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dZRi_yUEfGaF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n",
            "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x118245100>>\n"
          ]
        }
      ],
      "source": [
        "output_column=\"output\"\n",
        "gold_column=\"code\"\n",
        "  \n",
        "results = model_eval(\n",
        "    results_df=results_df,\n",
        "    parse_to_code=True,\n",
        "    compute_humanval=True,\n",
        "    compute_bleu=True,\n",
        "    output_column=output_column,\n",
        "    gold_column=gold_column,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9tgdrXxfP6H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python [conda env:biu] *",
      "language": "python",
      "name": "conda-env-biu-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10aea940ea6846d58b593191e881e613": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a28c771515745d1a181b10117df90e9",
            "placeholder": "​",
            "style": "IPY_MODEL_9d002f760db94ecf9269b5f3f274dd73",
            "value": " 23/23 [05:48&lt;00:00, 16.93s/it]"
          }
        },
        "1afa8c7b703148aca0ff450aeb01f875": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72cb47ec1a474d5ca9c8f27b4c5ce735",
            "placeholder": "​",
            "style": "IPY_MODEL_b52876e946f0469ea3653116f52f0eeb",
            "value": "100%"
          }
        },
        "1b093e57cb8e461e897a8ee742b9eaac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97256f5a7f584b92943ee8ed047f1736",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8c862162c71427ebc8d6b8980da0ff2",
            "value": 23
          }
        },
        "3f994969d7f7457098cbc0290a72c16f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a28c771515745d1a181b10117df90e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72cb47ec1a474d5ca9c8f27b4c5ce735": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76696e64a8a44f67989d5ed4b559b6f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1afa8c7b703148aca0ff450aeb01f875",
              "IPY_MODEL_1b093e57cb8e461e897a8ee742b9eaac",
              "IPY_MODEL_10aea940ea6846d58b593191e881e613"
            ],
            "layout": "IPY_MODEL_3f994969d7f7457098cbc0290a72c16f"
          }
        },
        "97256f5a7f584b92943ee8ed047f1736": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d002f760db94ecf9269b5f3f274dd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8c862162c71427ebc8d6b8980da0ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b52876e946f0469ea3653116f52f0eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
